diff --git a/export.py b/export.py
index e43d9b7..9b9c3ef 100644
--- a/export.py
+++ b/export.py
@@ -525,7 +525,7 @@ def run(
     if half:
         assert device.type != 'cpu' or coreml, '--half only compatible with GPU export, i.e. use --device 0'
         assert not dynamic, '--half not compatible with --dynamic, i.e. use either --half or --dynamic but not both'
-    model = attempt_load(weights, device=device, inplace=True, fuse=True)  # load FP32 model
+    model = attempt_load(weights, map_location=device, inplace=True, fuse=True)  # load FP32 model

     # Checks
     imgsz *= 2 if len(imgsz) == 1 else 1  # expand
@@ -549,7 +549,7 @@ def run(
         y = model(im)  # dry runs
     if half and not coreml:
         im, model = im.half(), model.half()  # to FP16
-    shape = tuple((y[0] if isinstance(y, tuple) else y).shape)  # model output shape
+    shape = tuple(y[0].shape)  # model output shape
     metadata = {'stride': int(max(model.stride)), 'names': model.names}  # model metadata
     LOGGER.info(f"\n{colorstr('PyTorch:')} starting from {file} with output shape {shape} ({file_size(file):.1f} MB)")

@@ -635,7 +635,7 @@ def parse_opt():
     parser.add_argument(
         '--include',
         nargs='+',
-        default=['torchscript'],
+        default=['onnx'],
         help='torchscript, onnx, openvino, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle')
     opt = parser.parse_args()
     print_args(vars(opt))
diff --git a/models/experimental.py b/models/experimental.py
index 02d35b9..cfa4db5 100644
--- a/models/experimental.py
+++ b/models/experimental.py
@@ -70,14 +70,14 @@ class Ensemble(nn.ModuleList):
         return y, None  # inference, train output


-def attempt_load(weights, device=None, inplace=True, fuse=True):
+def attempt_load(weights, map_location=None, inplace=True, fuse=True):
     # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a
     from models.yolo import Detect, Model

     model = Ensemble()
     for w in weights if isinstance(weights, list) else [weights]:
         ckpt = torch.load(attempt_download(w), map_location='cpu')  # load
-        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model
+        ckpt = (ckpt.get('ema') or ckpt['model']).to(map_location).float()  # FP32 model

         # Model compatibility updates
         if not hasattr(ckpt, 'stride'):
diff --git a/models/yolo.py b/models/yolo.py
index ed21c06..4ddfd6c 100644
--- a/models/yolo.py
+++ b/models/yolo.py
@@ -55,8 +55,11 @@ class Detect(nn.Module):

     def forward(self, x):
         z = []  # inference output
+        self.training = True
         for i in range(self.nl):
             x[i] = self.m[i](x[i])  # conv
+            if torch.onnx.is_in_onnx_export():
+                continue
             bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
             x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

